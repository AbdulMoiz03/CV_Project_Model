{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7d63514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Flask\n",
      "  Downloading flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Flask) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Flask) (3.1.4)\n",
      "Collecting itsdangerous>=2.2 (from Flask)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Flask) (8.1.7)\n",
      "Collecting blinker>=1.9 (from Flask)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (57.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click>=8.1.3->Flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Jinja2>=3.1.2->Flask) (3.0.2)\n",
      "Requirement already satisfied: rich in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hassan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: itsdangerous, blinker, Flask\n",
      "Successfully installed Flask-3.1.0 blinker-1.9.0 itsdangerous-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install Flask tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "977c9628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.1.7:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:192.168.1.7 - - [03/May/2025 13:55:29] \"\u001b[31m\u001b[1mGET /predict HTTP/1.1\u001b[0m\" 405 -\n",
      "INFO:werkzeug:192.168.1.7 - - [03/May/2025 13:55:29] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:192.168.1.7 - - [03/May/2025 13:55:33] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:192.168.1.7 - - [03/May/2025 13:55:38] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [03/May/2025 13:58:45] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [03/May/2025 13:58:45] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:192.168.1.7 - - [03/May/2025 14:09:53] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:192.168.1.7 - - [03/May/2025 14:09:53] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:192.168.1.7 - - [03/May/2025 14:10:01] \"\u001b[31m\u001b[1mGET /predict HTTP/1.1\u001b[0m\" 405 -\n",
      "INFO:werkzeug:192.168.1.11 - - [03/May/2025 14:10:39] \"\u001b[31m\u001b[1mGET /predict HTTP/1.1\u001b[0m\" 405 -\n",
      "INFO:werkzeug:192.168.1.11 - - [03/May/2025 14:10:40] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:192.168.1.11 - - [03/May/2025 14:10:58] \"\u001b[31m\u001b[1mGET /predict HTTP/1.1\u001b[0m\" 405 -\n",
      "ERROR:__main__:Exception on /predict [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"c:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"c:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"c:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "  File \"C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_26716\\103292873.py\", line 17, in predict\n",
      "    predictions = model.predict(img_array)\n",
      "  File \"c:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\models\\functional.py\", line 273, in _adjust_input_rank\n",
      "    raise ValueError(\n",
      "ValueError: Exception encountered when calling Sequential.call().\n",
      "\n",
      "\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(1, 224, 224, 3), dtype=float32). Expected shape (None, 1280), but input has incompatible shape (1, 224, 224, 3)\u001b[0m\n",
      "\n",
      "Arguments received by Sequential.call():\n",
      "  • inputs=tf.Tensor(shape=(1, 224, 224, 3), dtype=float32)\n",
      "  • training=False\n",
      "  • mask=None\n",
      "INFO:werkzeug:192.168.1.11 - - [03/May/2025 14:18:47] \"\u001b[35m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "app = Flask(__name__)\n",
    "model = load_model('landmark_recognition_model.h5')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    file = request.files['file']\n",
    "    img = Image.open(file.stream).resize((224, 224))  # Resize if needed\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "\n",
    "    return jsonify({'predicted_class': int(predicted_class)})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4ce6861",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.1.7:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:192.168.1.11 - - [03/May/2025 14:29:30] \"\u001b[35m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Initialize the Flask application\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('landmark_recognition_model.h5')  # Adjust the path if needed\n",
    "\n",
    "# Department label map\n",
    "label_map = {\n",
    "    0: \"BusinessDepartment\",\n",
    "    1: \"CivilDepartment\",\n",
    "    2: \"EEDepartment\",\n",
    "    3: \"Library\",\n",
    "    4: \"NewCSDepartment\",\n",
    "    5: \"OldCSDepartment\"\n",
    "}\n",
    "\n",
    "def load_and_preprocess(img_path):\n",
    "    \"\"\"\n",
    "    Function to load and preprocess image for MobileNetV2 model.\n",
    "    \"\"\"\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = preprocess_input(img_array)  # Preprocess image for MobileNetV2\n",
    "    return img_array\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        # Retrieve the image file from the request\n",
    "        file = request.files['file']\n",
    "\n",
    "        # Save the image temporarily for processing\n",
    "        img = Image.open(file.stream)\n",
    "        img_path = 'temp_image.jpg'\n",
    "        img.save(img_path)\n",
    "\n",
    "        # Preprocess the image\n",
    "        img_array = load_and_preprocess(img_path)\n",
    "\n",
    "        # Predict using the loaded model\n",
    "        predictions = model.predict(img_array)\n",
    "\n",
    "        # Get the class with the highest probability\n",
    "        predicted_class = np.argmax(predictions[0])\n",
    "\n",
    "        # Map the predicted class index to the corresponding label\n",
    "        predicted_label = label_map.get(predicted_class, \"Unknown\")\n",
    "\n",
    "        # Return the prediction in JSON format\n",
    "        return jsonify({'predicted_class': predicted_class, 'predicted_label': predicted_label})\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500  # Return error if something goes wrong\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "386e4f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.1.7:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:192.168.1.7 - - [03/May/2025 18:13:39] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import math\n",
    "import tempfile\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Global reference building sizes data\n",
    "REFERENCE_SIZES = {\n",
    "    'BusinessDepartment': {'height': 15.0, 'width': 40.0, 'reference_pixel_height': 450},\n",
    "    'Library': {'height': 11.0, 'width': 45.0, 'reference_pixel_height': 450},\n",
    "    'EEDepartment': {'height': 12.0, 'width': 50.0, 'reference_pixel_height': 450},\n",
    "    'CivilDepartment': {'height': 14.0, 'width': 50.0, 'reference_pixel_height': 500},\n",
    "    'OldCSDepartment': {'height': 15.0, 'width': 48.0, 'reference_pixel_height': 450},\n",
    "    'NewCSDepartment': {'height': 16.0, 'width': 50.0, 'reference_pixel_height': 500}\n",
    "}\n",
    "\n",
    "# Building coordinates for location estimation\n",
    "BUILDING_COORDINATES = {\n",
    "    'BusinessDepartment': (100, 200),\n",
    "    'EEDepartment': (280, 400),\n",
    "    'Library': (300, 150),\n",
    "    'OldCSDepartment': (250, 350),\n",
    "    'CivilDepartment': (150, 300),\n",
    "    'NewCSDepartment': (400, 250)\n",
    "}\n",
    "\n",
    "# Global model variables (will load on first request)\n",
    "recognition_model = None\n",
    "label_encoder = None\n",
    "base_model = None\n",
    "\n",
    "\n",
    "def load_recognition_model():\n",
    "    \"\"\"Loads the trained landmark recognition model\"\"\"\n",
    "    global recognition_model, label_encoder, base_model\n",
    "    \n",
    "    # Check if already loaded\n",
    "    if recognition_model is not None:\n",
    "        return recognition_model, label_encoder, base_model\n",
    "    \n",
    "    # Paths - adjust as needed for your deployment\n",
    "    model_path = 'landmark_recognition_model.h5'\n",
    "    annotations_path = \"annotations.csv\"\n",
    "    \n",
    "    # Load model\n",
    "    recognition_model = load_model(model_path)\n",
    "    \n",
    "    # Load annotations CSV\n",
    "    df = pd.read_csv(annotations_path)\n",
    "    \n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(df['building_name'])\n",
    "    \n",
    "    # Get base model for feature extraction\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(224, 224, 3),\n",
    "        pooling='avg'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    return recognition_model, label_encoder, base_model\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(img_path_or_data):\n",
    "    \"\"\"Load and preprocess image for the model from file path or image data\"\"\"\n",
    "    if isinstance(img_path_or_data, str):  # If path\n",
    "        img = image.load_img(img_path_or_data, target_size=(224, 224))\n",
    "    else:  # If image data\n",
    "        img = Image.open(io.BytesIO(img_path_or_data)).resize((224, 224))\n",
    "        \n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    return img_array, img\n",
    "\n",
    "\n",
    "def recognize_landmark(img_data, model, label_encoder, base_model):\n",
    "    \"\"\"Recognize landmark in the given image\"\"\"\n",
    "    # Preprocess image\n",
    "    preprocessed_img, original_img = load_and_preprocess_image(img_data)\n",
    "    \n",
    "    # Extract features\n",
    "    features = base_model.predict(preprocessed_img)\n",
    "    \n",
    "    # Predict building\n",
    "    prediction = model.predict(features)\n",
    "    predicted_class = np.argmax(prediction[0])\n",
    "    building_name = label_encoder.classes_[predicted_class]\n",
    "    confidence = float(prediction[0][predicted_class])\n",
    "    \n",
    "    return building_name, confidence, original_img\n",
    "\n",
    "\n",
    "def detect_building_boundaries(img_data):\n",
    "    \"\"\"\n",
    "    Detect the boundaries of a building in the image\n",
    "    Returns the bounding box coordinates and the building's height in pixels\n",
    "    \"\"\"\n",
    "    # Save image data to a temporary file if it's not already a file path\n",
    "    if not isinstance(img_data, str):\n",
    "        temp = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')\n",
    "        temp.write(img_data)\n",
    "        temp.close()\n",
    "        img_path = temp.name\n",
    "    else:\n",
    "        img_path = img_data\n",
    "    \n",
    "    # Read image\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not read image\")\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Edge detection using Canny\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    \n",
    "    # Dilate edges to connect broken lines\n",
    "    dilated = cv2.dilate(edges, np.ones((3, 3), np.uint8), iterations=2)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Find the largest contour (assuming it's the building)\n",
    "    if not contours:\n",
    "        return None, 0, img_rgb\n",
    "    \n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Get bounding box\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    \n",
    "    # Clean up temporary file if created\n",
    "    if not isinstance(img_data, str):\n",
    "        os.unlink(img_path)\n",
    "    \n",
    "    return (x, y, w, h), h, img_rgb\n",
    "\n",
    "\n",
    "def estimate_distance_by_size(building_name, pixel_height):\n",
    "    \"\"\"\n",
    "    Estimate the distance to a building based on its apparent size in pixels\n",
    "    compared to a reference size.\n",
    "    \"\"\"\n",
    "    if building_name not in REFERENCE_SIZES:\n",
    "        return None\n",
    "    \n",
    "    # Get reference measurements for this building\n",
    "    reference_data = REFERENCE_SIZES[building_name]\n",
    "    reference_height_m = reference_data['height']\n",
    "    reference_pixel_height = reference_data['reference_pixel_height']\n",
    "    \n",
    "    # Calculate focal length from reference data\n",
    "    # Assumes reference image was taken at a known distance (e.g., 10 meters)\n",
    "    reference_distance = 10.0  # meters\n",
    "    focal_length = (reference_pixel_height * reference_distance) / reference_height_m\n",
    "    \n",
    "    # Calculate distance using the focal length and current pixel height\n",
    "    estimated_distance = (reference_height_m * focal_length) / pixel_height\n",
    "    \n",
    "    return estimated_distance\n",
    "\n",
    "\n",
    "def estimate_triangulation_distance(img_data1, img_data2, baseline_distance):\n",
    "    \"\"\"\n",
    "    Estimate distance using triangulation from two images taken at known distance apart\n",
    "    \"\"\"\n",
    "    # Save image data to temporary files\n",
    "    temp1 = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')\n",
    "    temp1.write(img_data1)\n",
    "    temp1.close()\n",
    "    \n",
    "    temp2 = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')\n",
    "    temp2.write(img_data2)\n",
    "    temp2.close()\n",
    "    \n",
    "    # Detect building in both images\n",
    "    bbox1, height1, _ = detect_building_boundaries(temp1.name)\n",
    "    bbox2, height2, _ = detect_building_boundaries(temp2.name)\n",
    "    \n",
    "    # Clean up temporary files\n",
    "    os.unlink(temp1.name)\n",
    "    os.unlink(temp2.name)\n",
    "    \n",
    "    if bbox1 is None or bbox2 is None:\n",
    "        return None\n",
    "    \n",
    "    # Calculate image centers (width)\n",
    "    img1 = cv2.imread(temp1.name)\n",
    "    img2 = cv2.imread(temp2.name)\n",
    "    img_center1 = img1.shape[1] / 2\n",
    "    img_center2 = img2.shape[1] / 2\n",
    "    \n",
    "    # Calculate building centers in both images\n",
    "    building_center1 = bbox1[0] + bbox1[2]/2\n",
    "    building_center2 = bbox2[0] + bbox2[2]/2\n",
    "    \n",
    "    # Calculate parallax (difference in position)\n",
    "    parallax1 = building_center1 - img_center1\n",
    "    parallax2 = building_center2 - img_center2\n",
    "    \n",
    "    # Calculate change in parallax\n",
    "    parallax_change = abs(parallax1 - parallax2)\n",
    "    \n",
    "    if parallax_change == 0:\n",
    "        # Avoid division by zero\n",
    "        return None\n",
    "    \n",
    "    # Calculate distance using triangulation formula\n",
    "    # Distance = (baseline * focal_length) / parallax_change\n",
    "    # Assuming focal_length is approximately image_width for simplicity\n",
    "    focal_length = img1.shape[1]\n",
    "    distance = (baseline_distance * focal_length) / parallax_change\n",
    "    \n",
    "    return distance\n",
    "\n",
    "\n",
    "def estimate_location(building_name, distance, bearing=None):\n",
    "    \"\"\"\n",
    "    Estimate user's location based on distance to a landmark and optional bearing\n",
    "    \"\"\"\n",
    "    if building_name not in BUILDING_COORDINATES:\n",
    "        return None\n",
    "    \n",
    "    building_x, building_y = BUILDING_COORDINATES[building_name]\n",
    "    \n",
    "    if bearing is None:\n",
    "        # Without bearings, default to south of the building\n",
    "        angle_rad = math.radians(180)\n",
    "    else:\n",
    "        # Convert bearings to radians for calculation\n",
    "        angle_rad = math.radians(bearing)\n",
    "    \n",
    "    # Calculate position\n",
    "    x = building_x - distance * math.sin(angle_rad)\n",
    "    y = building_y + distance * math.cos(angle_rad)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "\n",
    "def get_image_from_request():\n",
    "    \"\"\"Extract image data from request (base64 or file upload)\"\"\"\n",
    "    if 'file' in request.files:\n",
    "        # File upload\n",
    "        file = request.files['file']\n",
    "        return file.read()\n",
    "    elif 'image' in request.json:\n",
    "        # Base64 encoded image\n",
    "        base64_data = request.json['image']\n",
    "        # Remove the data URI prefix if present (e.g., \"data:image/jpeg;base64,\")\n",
    "        if ',' in base64_data:\n",
    "            base64_data = base64_data.split(',', 1)[1]\n",
    "        return base64.b64decode(base64_data)\n",
    "    else:\n",
    "        raise ValueError(\"No image data found in request\")\n",
    "\n",
    "\n",
    "@app.route('/api/recognize', methods=['POST'])\n",
    "def api_recognize():\n",
    "    \"\"\"API endpoint for landmark recognition\"\"\"\n",
    "    try:\n",
    "        # Load models if not already loaded\n",
    "        global recognition_model, label_encoder, base_model\n",
    "        if recognition_model is None:\n",
    "            recognition_model, label_encoder, base_model = load_recognition_model()\n",
    "        \n",
    "        # Get image data from request\n",
    "        img_data = get_image_from_request()\n",
    "        \n",
    "        # Recognize landmark\n",
    "        building_name, confidence, _ = recognize_landmark(img_data, recognition_model, label_encoder, base_model)\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'building_name': building_name,\n",
    "            'confidence': confidence\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 400\n",
    "\n",
    "\n",
    "@app.route('/api/estimate-distance', methods=['POST'])\n",
    "def api_estimate_distance():\n",
    "    \"\"\"API endpoint for distance estimation\"\"\"\n",
    "    try:\n",
    "        # Load models if not already loaded\n",
    "        global recognition_model, label_encoder, base_model\n",
    "        if recognition_model is None:\n",
    "            recognition_model, label_encoder, base_model = load_recognition_model()\n",
    "        \n",
    "        # Get image data from request\n",
    "        img_data = get_image_from_request()\n",
    "        \n",
    "        # Recognize landmark\n",
    "        building_name, confidence, _ = recognize_landmark(img_data, recognition_model, label_encoder, base_model)\n",
    "        \n",
    "        # Detect building boundaries\n",
    "        bbox, pixel_height, _ = detect_building_boundaries(img_data)\n",
    "        \n",
    "        if bbox is None:\n",
    "            return jsonify({\n",
    "                'success': False,\n",
    "                'error': 'Could not detect building boundaries'\n",
    "            }), 400\n",
    "        \n",
    "        # Estimate distance\n",
    "        distance = estimate_distance_by_size(building_name, pixel_height)\n",
    "        \n",
    "        if distance is None:\n",
    "            return jsonify({\n",
    "                'success': False,\n",
    "                'error': f'No reference data available for {building_name}'\n",
    "            }), 400\n",
    "        \n",
    "        # Estimate location if bearing provided\n",
    "        location = None\n",
    "        if 'bearing' in request.json:\n",
    "            bearing = float(request.json['bearing'])\n",
    "            user_x, user_y = estimate_location(building_name, distance, bearing)\n",
    "            location = {'x': user_x, 'y': user_y}\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'building_name': building_name,\n",
    "            'confidence': confidence,\n",
    "            'distance': distance,\n",
    "            'location': location\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 400\n",
    "\n",
    "\n",
    "@app.route('/api/triangulate', methods=['POST'])\n",
    "def api_triangulate():\n",
    "    \"\"\"API endpoint for triangulation-based distance estimation\"\"\"\n",
    "    try:\n",
    "        # Validate request\n",
    "        if 'image1' not in request.json or 'image2' not in request.json or 'baseline' not in request.json:\n",
    "            return jsonify({\n",
    "                'success': False,\n",
    "                'error': 'Missing required parameters: image1, image2, and baseline'\n",
    "            }), 400\n",
    "        \n",
    "        # Get image data from request\n",
    "        img_data1 = base64.b64decode(request.json['image1'])\n",
    "        img_data2 = base64.b64decode(request.json['image2'])\n",
    "        baseline = float(request.json['baseline'])\n",
    "        \n",
    "        # Estimate distance using triangulation\n",
    "        distance = estimate_triangulation_distance(img_data1, img_data2, baseline)\n",
    "        \n",
    "        if distance is None:\n",
    "            return jsonify({\n",
    "                'success': False,\n",
    "                'error': 'Triangulation failed'\n",
    "            }), 400\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'distance': distance\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 400\n",
    "\n",
    "\n",
    "@app.route('/api/location', methods=['POST'])\n",
    "def api_location():\n",
    "    \"\"\"API endpoint for user location estimation\"\"\"\n",
    "    try:\n",
    "        # Validate request\n",
    "        if 'building_name' not in request.json or 'distance' not in request.json:\n",
    "            return jsonify({\n",
    "                'success': False,\n",
    "                'error': 'Missing required parameters: building_name and distance'\n",
    "            }), 400\n",
    "        \n",
    "        building_name = request.json['building_name']\n",
    "        distance = float(request.json['distance'])\n",
    "        bearing = None\n",
    "        if 'bearing' in request.json:\n",
    "            bearing = float(request.json['bearing'])\n",
    "        \n",
    "        # Estimate location\n",
    "        location = estimate_location(building_name, distance, bearing)\n",
    "        \n",
    "        if location is None:\n",
    "            return jsonify({\n",
    "                'success': False,\n",
    "                'error': f'Could not estimate location for {building_name}'\n",
    "            }), 400\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'x': location[0],\n",
    "            'y': location[1],\n",
    "            'building_coordinates': BUILDING_COORDINATES[building_name]\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 400\n",
    "\n",
    "\n",
    "@app.route('/api/all-in-one', methods=['POST'])\n",
    "def api_all_in_one():\n",
    "    \"\"\"Comprehensive API endpoint that performs recognition, distance estimation, and location in one call\"\"\"\n",
    "    try:\n",
    "        # Load models if not already loaded\n",
    "        global recognition_model, label_encoder, base_model\n",
    "        if recognition_model is None:\n",
    "            recognition_model, label_encoder, base_model = load_recognition_model()\n",
    "        \n",
    "        # Get image data from request\n",
    "        img_data = get_image_from_request()\n",
    "        \n",
    "        # Recognize landmark\n",
    "        building_name, confidence, _ = recognize_landmark(img_data, recognition_model, label_encoder, base_model)\n",
    "        \n",
    "        # Detect building boundaries\n",
    "        bbox, pixel_height, _ = detect_building_boundaries(img_data)\n",
    "        \n",
    "        if bbox is None:\n",
    "            return jsonify({\n",
    "                'success': False,\n",
    "                'error': 'Could not detect building boundaries'\n",
    "            }), 400\n",
    "        \n",
    "        # Estimate distance\n",
    "        distance = estimate_distance_by_size(building_name, pixel_height)\n",
    "        \n",
    "        if distance is None:\n",
    "            return jsonify({\n",
    "                'success': False,\n",
    "                'error': f'No reference data available for {building_name}'\n",
    "            }), 400\n",
    "        \n",
    "        # Estimate location if bearing provided\n",
    "        location = None\n",
    "        if 'bearing' in request.json:\n",
    "            bearing = float(request.json['bearing'])\n",
    "            user_x, user_y = estimate_location(building_name, distance, bearing)\n",
    "            location = {'x': user_x, 'y': user_y}\n",
    "        \n",
    "        # Prepare response with all data\n",
    "        response = {\n",
    "            'success': True,\n",
    "            'recognition': {\n",
    "                'building_name': building_name,\n",
    "                'confidence': confidence\n",
    "            },\n",
    "            'building_details': {\n",
    "                'reference_height': REFERENCE_SIZES[building_name]['height'],\n",
    "                'reference_width': REFERENCE_SIZES[building_name]['width'],\n",
    "                'pixel_height': pixel_height,\n",
    "                'bounding_box': {\n",
    "                    'x': bbox[0],\n",
    "                    'y': bbox[1],\n",
    "                    'width': bbox[2],\n",
    "                    'height': bbox[3]\n",
    "                }\n",
    "            },\n",
    "            'distance': {\n",
    "                'value': distance,\n",
    "                'unit': 'meters'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if location:\n",
    "            response['location'] = location\n",
    "            response['building_coordinates'] = BUILDING_COORDINATES[building_name]\n",
    "        print(response)\n",
    "        return jsonify(response)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 400\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load models at startup\n",
    "    recognition_model, label_encoder, base_model = load_recognition_model()\n",
    "    app.run(host='0.0.0.0', port=5000, debug=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
