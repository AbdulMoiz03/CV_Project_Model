{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f04c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a61a4d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "REFERENCE_SIZES = {\n",
    "    'BusinessDepartment': {'height': 15.0, 'width': 40.0, 'reference_pixel_height': 450},\n",
    "    'Library': {'height': 11.0, 'width': 45.0, 'reference_pixel_height': 450},\n",
    "    'EEDepartment': {'height': 12.0, 'width': 50.0, 'reference_pixel_height': 450},\n",
    "    'CivilDepartment': {'height': 14.0, 'width': 50.0, 'reference_pixel_height': 500},\n",
    "    'OldCSDepartment': {'height': 15.0, 'width': 48.0, 'reference_pixel_height': 450},\n",
    "    'NewCSDepartment': {'height': 16.0, 'width': 50.0, 'reference_pixel_height': 500}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "722bf6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_recognition_model():\n",
    "    \"\"\"Loads the trained landmark recognition model\"\"\"\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    from tensorflow.keras.models import load_model\n",
    "    import tensorflow as tf\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    # from google.colab import files\n",
    "\n",
    "    model_path = 'model/landmark_recognition_model.h5'\n",
    "    if not os.path.exists(model_path):\n",
    "        model_path = 'landmark_recognition_model.h5'\n",
    "        if not os.path.exists(model_path):\n",
    "            print(\"Model file not found. Please upload your model file:\")\n",
    "            uploaded = files.upload()\n",
    "            model_path = list(uploaded.keys())[0]\n",
    "\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    annotations_path = \"annotations/annotations.csv\"\n",
    "    if not os.path.exists(annotations_path):\n",
    "        annotations_path = \"annotations.csv\"\n",
    "        if not os.path.exists(annotations_path):\n",
    "            print(\"Annotations CSV not found. Please upload your annotations file:\")\n",
    "            uploaded = files.upload()\n",
    "            annotations_path = list(uploaded.keys())[0]\n",
    "\n",
    "    df = pd.read_csv(annotations_path)\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(df['building_name'])\n",
    "\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(224, 224, 3),\n",
    "        pooling='avg'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    return model, label_encoder, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1de483dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(img_path):\n",
    "    \"\"\"Load and preprocess image for the model\"\"\"\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "    import numpy as np\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    return img_array, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1632a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_landmark(img_path, model, label_encoder, base_model):\n",
    "    \"\"\"Recognize landmark in the given image\"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    preprocessed_img, original_img = load_and_preprocess_image(img_path)\n",
    "    features = base_model.predict(preprocessed_img)\n",
    "    prediction = model.predict(features)\n",
    "    predicted_class = np.argmax(prediction[0])\n",
    "    building_name = label_encoder.classes_[predicted_class]\n",
    "    confidence = prediction[0][predicted_class]\n",
    "\n",
    "    return building_name, confidence, original_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "969cee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_building_boundaries(image_path):\n",
    "    \"\"\"Detect the boundaries of a building in the image\"\"\"\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not read image at path: {image_path}\")\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    dilated = cv2.dilate(edges, np.ones((3, 3), np.uint8), iterations=2)\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if not contours:\n",
    "        return None, 0, img_rgb\n",
    "\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    cv2.rectangle(img_rgb, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    return (x, y, w, h), h, img_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c1b4ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_distance_by_size(building_name, pixel_height):\n",
    "    \"\"\"Estimate the distance to a building based on its apparent size in pixels\"\"\"\n",
    "    if building_name not in REFERENCE_SIZES:\n",
    "        return None\n",
    "\n",
    "    reference_data = REFERENCE_SIZES[building_name]\n",
    "    reference_height_m = reference_data['height']\n",
    "    reference_pixel_height = reference_data['reference_pixel_height']\n",
    "    reference_distance = 10.0  # meters\n",
    "    focal_length = (reference_pixel_height * reference_distance) / reference_height_m\n",
    "    estimated_distance = (reference_height_m * focal_length) / pixel_height\n",
    "\n",
    "    return estimated_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "746cf30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_location_by_trilateration(buildings, distances):\n",
    "    \"\"\"Estimate user location using trilateration from three buildings\"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    BUILDING_COORDINATES = {\n",
    "        'BusinessDepartment': (100, 200),\n",
    "        'EEDepartment': (280, 400),\n",
    "        'Library': (300, 150),\n",
    "        'OldCSDepartment': (250, 350),\n",
    "        'CivilDepartment': (150, 300),\n",
    "        'NewCSDepartment': (400, 250)\n",
    "    }\n",
    "\n",
    "    if len(buildings) != 3 or len(distances) != 3:\n",
    "        return None\n",
    "\n",
    "    for building in buildings:\n",
    "        if building not in BUILDING_COORDINATES:\n",
    "            return None\n",
    "\n",
    "    # Extract coordinates and distances\n",
    "    x1, y1 = BUILDING_COORDINATES[buildings[0]]\n",
    "    x2, y2 = BUILDING_COORDINATES[buildings[1]]\n",
    "    x3, y3 = BUILDING_COORDINATES[buildings[2]]\n",
    "    r1, r2, r3 = distances\n",
    "\n",
    "    # Trilateration equations: solve for (x, y)\n",
    "    # (x - x1)^2 + (y - y1)^2 = r1^2\n",
    "    # (x - x2)^2 + (y - y2)^2 = r2^2\n",
    "    # (x - x3)^2 + (y - y3)^2 = r3^2\n",
    "    # Use linearization to solve\n",
    "    A = np.array([\n",
    "        [2*(x1 - x3), 2*(y1 - y3)],\n",
    "        [2*(x2 - x3), 2*(y2 - y3)]\n",
    "    ])\n",
    "    B = np.array([\n",
    "        [r3**2 - r1**2 - x3**2 + x1**2 - y3**2 + y1**2],\n",
    "        [r3**2 - r2**2 - x3**2 + x2**2 - y3**2 + y2**2]\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        X = np.linalg.solve(A, B)\n",
    "        x, y = X[0][0], X[1][0]\n",
    "        return (x, y)\n",
    "    except np.linalg.LinAlgError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "911f8456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(img_rgb, building_name, confidence, distance):\n",
    "    \"\"\"Display the image with detected building and estimated distance\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(f\"Detected: {building_name} (Confidence: {confidence:.2f})\")\n",
    "    plt.xlabel(f\"Estimated Distance: {distance:.2f} meters\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0139145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_location(building_names, distances, bearings=None):\n",
    "    \"\"\"Estimate user's location based on distances to landmarks\"\"\"\n",
    "    import math\n",
    "\n",
    "    BUILDING_COORDINATES = {\n",
    "        'BusinessDepartment': (100, 200),\n",
    "        'EEDepartment': (280, 400),\n",
    "        'Library': (300, 150),\n",
    "        'OldCSDepartment': (250, 350),\n",
    "        'CivilDepartment': (150, 300),\n",
    "        'NewCSDepartment': (400, 250)\n",
    "    }\n",
    "\n",
    "    if len(building_names) >= 3:\n",
    "        # Use trilateration for three or more buildings\n",
    "        return estimate_location_by_trilateration(building_names[:3], distances[:3])\n",
    "    elif len(building_names) == 1:\n",
    "        # Fallback to single building estimation\n",
    "        building_name = building_names[0]\n",
    "        distance = distances[0]\n",
    "        if building_name not in BUILDING_COORDINATES:\n",
    "            return None\n",
    "\n",
    "        building_x, building_y = BUILDING_COORDINATES[building_name]\n",
    "        if bearings is None:\n",
    "            angle_rad = math.radians(180)  # Default to south\n",
    "        else:\n",
    "            angle_rad = math.radians(bearings[0])\n",
    "\n",
    "        x = building_x - distance * math.sin(angle_rad)\n",
    "        y = building_y + distance * math.cos(angle_rad)\n",
    "        return x, y\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80dd5cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_location_on_map(user_location, building_coordinates, detected_building=None, filename=None):\n",
    "    import folium\n",
    "    import os\n",
    "    import uuid\n",
    "\n",
    "    m = folium.Map(location=user_location, zoom_start=18)\n",
    "    folium.Marker(user_location, tooltip=\"Estimated Location\", icon=folium.Icon(color=\"red\")).add_to(m)\n",
    "\n",
    "    for building_name, coords in building_coordinates.items():\n",
    "        folium.Marker(\n",
    "            location=coords,\n",
    "            tooltip=building_name,\n",
    "            icon=folium.Icon(color=\"blue\", icon=\"info-sign\")\n",
    "        ).add_to(m)\n",
    "\n",
    "    if detected_building and detected_building in building_coordinates:\n",
    "        folium.PolyLine(locations=[user_location, building_coordinates[detected_building]],\n",
    "                        color='green', weight=2.5, opacity=0.8).add_to(m)\n",
    "\n",
    "    if not filename:\n",
    "        filename = f\"map_{uuid.uuid4().hex}.html\"\n",
    "    save_path = os.path.join(\"static\", \"maps\", filename)\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    m.save(save_path)\n",
    "\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ec166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.1.18:5000\n",
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.1.18:5000\n",
      "Press CTRL+C to quit\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F302ABD240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F302ABD240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.17 - - [13/May/2025 23:57:58] \"POST /process-images HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:192.168.1.17 - - [13/May/2025 23:57:58] \"POST /process-images HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'results': [{'image_index': 0, 'building_name': 'EEDepartment', 'confidence': '0.8130387', 'bounding_box': '(1712, 2182, 870, 157)', 'pixel_height': '157', 'distance': '28.662420382165607'}, {'image_index': 1, 'building_name': 'BusinessDepartment', 'confidence': '0.638093', 'bounding_box': '(2868, 411, 209, 1358)', 'pixel_height': '1358', 'distance': '3.313696612665685'}, {'image_index': 2, 'building_name': 'BusinessDepartment', 'confidence': '0.86560667', 'bounding_box': '(324, 2526, 3132, 56)', 'pixel_height': '56', 'distance': '80.35714285714286'}], 'user_location': 'None', 'map_url': 'None'}\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import nest_asyncio\n",
    "from pyngrok import ngrok\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/process-images', methods=['POST'])\n",
    "def process_images():\n",
    "    model, label_encoder, base_model = load_recognition_model()\n",
    "    BUILDING_COORDINATES = {\n",
    "        'BusinessDepartment': (100, 200),\n",
    "        'EEDepartment': (280, 400),\n",
    "        'Library': (300, 150),\n",
    "        'OldCSDepartment': (250, 350),\n",
    "        'CivilDepartment': (150, 300),\n",
    "        'NewCSDepartment': (400, 250)\n",
    "    }\n",
    "\n",
    "    if 'images' not in request.files:\n",
    "        return jsonify({'error': 'No images provided'}), 400\n",
    "\n",
    "    images = request.files.getlist('images')\n",
    "    if len(images) < 1 or len(images) > 3:\n",
    "        return jsonify({'error': 'Please provide 1 to 3 images'}), 400\n",
    "\n",
    "    results = []\n",
    "    building_names = []\n",
    "    distances = []\n",
    "\n",
    "    for idx, img_file in enumerate(images):\n",
    "        img_path = f'temp_image_{uuid.uuid4().hex}.jpg'\n",
    "        img_file.save(img_path)\n",
    "\n",
    "        try:\n",
    "            building_name, confidence, original_img = recognize_landmark(img_path, model, label_encoder, base_model)\n",
    "            bbox, pixel_height, img_rgb = detect_building_boundaries(img_path)\n",
    "            distance = estimate_distance_by_size(building_name, pixel_height) if pixel_height > 0 else None\n",
    "\n",
    "            result = {\n",
    "                'image_index': idx,\n",
    "                'building_name': building_name,\n",
    "                'confidence': str(confidence),\n",
    "                'bounding_box': str(bbox),\n",
    "                'pixel_height': str(pixel_height),\n",
    "                'distance': str(distance) if distance else 'None'\n",
    "            }\n",
    "\n",
    "            building_names.append(building_name)\n",
    "            distances.append(distance if distance else 0)\n",
    "            results.append(result)\n",
    "\n",
    "        finally:\n",
    "            if os.path.exists(img_path):\n",
    "                os.remove(img_path)\n",
    "\n",
    "    user_location = estimate_location(building_names, distances)\n",
    "    print(user_location)\n",
    "    map_filename = None\n",
    "    if user_location:\n",
    "        map_filename = visualize_location_on_map(user_location, BUILDING_COORDINATES, building_names[0] if len(building_names) == 1 else None)\n",
    "        map_url = f\"http://127.0.0.1:5000/static/maps/{map_filename}\"\n",
    "    else:\n",
    "        map_url = 'None'\n",
    "\n",
    "    response = {\n",
    "        'results': results,\n",
    "        'user_location': str(user_location) if user_location else 'None',\n",
    "        'map_url': map_url\n",
    "    }\n",
    "    print(response)\n",
    "    return jsonify(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    nest_asyncio.apply()\n",
    "    app.run(host='0.0.0.0', port=5000, debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
